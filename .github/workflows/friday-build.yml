name: IW Bot — Friday Build

on:
  schedule:
    - cron: "25 21 * * 5"     # Friday after U.S. close (EST)
    - cron: "25 20 * * 5"     # Friday after U.S. close (EDT)
  workflow_dispatch:
    inputs:
      topk:
        description: "Top-K to preview/email"
        required: false
        default: "6"
      hi70_preview:
        description: "Optional comma-separated 70D tickers to include (testing only)"
        required: false
        default: ""
        

concurrency:
  group: iwbot-friday-build
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read   # <— required to download artifacts from other workflow runs
    env:
      TOPK:  ${{ inputs.topk != '' && inputs.topk || '6' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: |
          python -m pip install --upgrade pip
          pip install pandas numpy pyyaml requests
      - name: Compute last Friday (Europe/Oslo)
        id: when
        shell: python
        run: |
          from datetime import datetime, timedelta
          import zoneinfo, os, json
          tz=zoneinfo.ZoneInfo("Europe/Oslo"); now=datetime.now(tz).date()
          while now.weekday()!=4: now-=timedelta(days=1)
          mon=(now+timedelta(days=3)).isoformat()
          with open("runner_dates.json","w") as f:
              json.dump({"friday":now.isoformat(),"monday":mon},f)
          with open(os.environ["GITHUB_OUTPUT"],"a") as g:
              g.write(f"friday={now}\n")
              g.write(f"monday={mon}\n")   # <-- add this line
      
      - name: Export WEEK (nominal Monday) for later steps
        run: echo "WEEK=${{ steps.when.outputs.monday }}" >> $GITHUB_ENV

      
      
      - name: Cache dataset between runs
        uses: actions/cache@v4
        with:
          path: stock_data_400
          key: polygon-dataset-${{ steps.when.outputs.friday }}
          restore-keys: polygon-dataset-
      - name: Fetch dataset + build picklist
        run: |
          python build_picklist_parametric.py \
            --data-dir stock_data_400 \
            --rsi-min 68 --max-ext20 0.15 --top-per-week 40 \
            --until "${{ steps.when.outputs.friday }}" \
            --out backtests/picklist_highrsi_trend.csv

      # NEW — build dynamic universe (same thresholds as hi70)
      - name: Build dynamic universe (Top-N by ADV$)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python tools/make_universe_topvol.py \
            --adv-days 21 \
            --topvol 1000 \
            --min-price 5 \
            --out-dir backtests
          echo "[universe] count: $(wc -l < backtests/universe_topvol.txt)"
          sed -n '1,8p' backtests/universe_topvol.csv



      - name: Filter:light short-term trend (no ≥2 consecutive down weeks)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python tools/filter_trend_light.py \
            --picklist backtests/picklist_highrsi_trend.csv \
            --out      backtests/picklist_highrsi_trend.csv \
            --anchor-friday "${{ steps.when.outputs.friday }}" \
            --weeks 4 \
            --max-consecutive-down 1 \
            --down-eps 0.002

      
      # NEW — filter picklist to that universe (no ranking changes)
      - name: Filter picklist by dynamic universe
        run: |
          python tools/filter_picklist_by_symbols.py \
            backtests/universe_topvol.txt \
            backtests/picklist_highrsi_trend.csv \
            backtests/picklist_highrsi_trend.csv


      - name: Filter hi70 results to shared universe
        run: |
          python tools/filter_picklist_by_symbols.py \
            backtests/universe_topvol.txt \
            backtests/hi70_thisweek.csv \
            backtests/hi70_thisweek.csv
          echo "[hi70] head after filter:"
          sed -n '1,12p' backtests/hi70_thisweek.csv

      
      - name: Preview Top-K (save file)
        run: |
          set -e
           python preview_top6.py \
            --picklist backtests/picklist_highrsi_trend.csv \
            --topk "${{ inputs.topk != '' && inputs.topk || '6' }}" \
            --week "${{ steps.when.outputs.friday }}" \
            > backtests/top6_preview.txt

      - name: Download 70D-highs artifact (if available)
        if: always()
        uses: dawidd6/action-download-artifact@v2
        with:
          repo: ${{ github.repository }}
          workflow: hi70-scan.yml           # the workflow that builds the 70D-highs artifact
          workflow_conclusion: success
          branch: main
          name_is_regexp: true
          name: ^hi70-.*$                   # match any hi70-* artifact name
          path: backtests
          allow_forks: true
          if_no_artifact_found: warn        # <- don't fail the job if it’s missing

      - name: Probe hi70 artifact contents
        shell: bash
        run: |
          set -e
          echo "[probe] Listing backtests/"
          find backtests -maxdepth 2 -type f -name 'hi70_*' -printf '%p  (%s bytes)\n' | sort || true
          HI70_CSV="$(find backtests -type f -name 'hi70_thisweek.csv' -print -quit || true)"
          if [ -n "$HI70_CSV" ]; then
            echo "[probe] Head of $HI70_CSV"
            sed -n '1,12p' "$HI70_CSV" || true
            echo "[probe] Row count (excluding header):"
            awk -F, 'NR>1 && $1!="" {c++} END{print c+0}' "$HI70_CSV" || true
          fi
          HI70_TXT="$(find backtests -type f -name 'hi70_digest.txt' -print -quit || true)"
          if [ -n "$HI70_TXT" ]; then
            echo "[probe] Head of $HI70_TXT"
            sed -n '1,12p' "$HI70_TXT" || true
          fi

      - name: Append Top-10 70D highs to email body
        shell: bash
        run: |
          set -e
          if [ -f backtests/hi70_thisweek.csv ]; then
            TICKERS=$(awk -F, 'NR>1 && $1!="" {print $1}' backtests/hi70_thisweek.csv | head -10 | paste -sd ', ' -)
            {
              echo 'EMAIL_BODY<<EOF'
              echo -e "${EMAIL_BODY}\n\nTop-10 70D highs: ${TICKERS}"
              echo 'EOF'
            } >> "$GITHUB_ENV"
            echo "[email] Added 70D list: ${TICKERS}"
          else
            echo "[email] hi70 CSV not found; leaving email body as-is."
          fi


      - name: Options snapshot — Picks (disabled)
        run: echo "Options snapshot disabled for now."

      - name: Options snapshot — 70D breakouts (disabled)
        run: echo "Options snapshot disabled for now."

      - name: Compose email body (weekly picks + Top-10 70D highs)
        shell: bash
        run: |
          set -euo pipefail
      
          BODY="IW Bot — Weekly picks for ${{ steps.when.outputs.friday }}"
      
          # Top-K preview (if present)
          if [[ -f backtests/top6_preview.txt ]]; then
            BODY+=$'\n\n'
            BODY+="$(< backtests/top6_preview.txt)"
          else
            BODY+=$'\n\n(no Top-K preview file found)'
          fi
      
          # Locate hi70 CSV (top-level or dated subfolder)
          CSV=""
          for p in backtests/hi70_thisweek.csv backtests/hi70-*/hi70_thisweek.csv; do
            [[ -f "$p" ]] && { CSV="$p"; break; }
          done
      
          if [[ -n "$CSV" ]]; then
            TICKERS=$(awk -F, 'NR>1 && $1!="" {print $1}' "$CSV" | head -10 | paste -sd ', ' -)
            BODY+=$'\n\nTop-10 70D Highs: '
            if [[ -n "$TICKERS" ]]; then
              BODY+="$TICKERS"
            else
              BODY+='(none this week)'
            fi
          else
            BODY+=$'\n\nTop-10 70D Highs: (files not found in this run)'
          fi
      
          {
            echo "EMAIL_BODY<<EOF"
            printf '%s\n' "$BODY"
            echo "EOF"
          } >> "$GITHUB_ENV"
      
          echo "[email] using CSV: ${CSV:-'(not found)'}"
          echo "[email] body preview (first 400 chars):"
          echo "${BODY:0:400}"









      - name: Email config (from secrets)
        run: |
            cat > config_notify.yaml <<'YAML'
             # primary keys
            smtp_user: ${{ secrets.SMTP_USER }}
             smtp_pass: ${{ secrets.SMTP_PASS }}
            smtp_from: ${{ secrets.SMTP_FROM }}
             smtp_to:   ${{ secrets.SMTP_TO }}
             host: smtp.gmail.com
             port: 587
            use_tls: true
      
             # aliases some scripts expect
            from: ${{ secrets.SMTP_FROM }}
            to:   ${{ secrets.SMTP_TO }}
            YAML

      - name: Probe Gmail SMTP login
        shell: python
        env:
          SMTP_HOST: smtp.gmail.com
          SMTP_PORT: "587"
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
        run: |
          import os, smtplib
          missing=[k for k in ["SMTP_HOST","SMTP_PORT","SMTP_USER","SMTP_PASS"] if not os.getenv(k)]
          print("[email] present keys:", [k for k in ["SMTP_HOST","SMTP_PORT","SMTP_USER","SMTP_PASS"] if os.getenv(k)])
          print("[email] missing keys:", missing)
          if missing: raise SystemExit("Missing SMTP secrets")
          with smtplib.SMTP(os.environ["SMTP_HOST"], int(os.environ["SMTP_PORT"])) as s:
              s.ehlo(); s.starttls(); s.ehlo()
              s.login(os.environ["SMTP_USER"], os.environ["SMTP_PASS"])
          print("SMTP login OK ✅")


      - name: Email weekly summary (picks + 70D highs)
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          secure: false
          username: ${{ secrets.SMTP_USER }}
          password: ${{ secrets.SMTP_PASS }}
          subject: "IW Bot — Weekly Picks ${{ steps.when.outputs.friday }}"
          from: ${{ secrets.SMTP_FROM }}
          to: ${{ secrets.SMTP_TO }}
          body: ${{ env.EMAIL_BODY }}




      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: weekly-picks-${{ steps.when.outputs.friday }}
          path: |
            backtests/picklist_highrsi_trend.csv
            backtests/top6_preview.txt
            runner_dates.json
